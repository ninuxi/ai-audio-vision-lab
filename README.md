# ğŸ›ï¸ AI Audio Vision Lab

![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-4-green)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![AI](https://img.shields.io/badge/AI-PyTorch%20%2B%20Magenta-orange)

<div align="center">
  <img src="docs/images/ai-audio-vision-device.png" alt="AI Audio Vision Lab Device" width="400"/>
</div>

> **ğŸ‡¬ğŸ‡§ An innovative AI system that transforms vision into music**  
> Real-time object recognition and coherent music generation, running completely offline on Raspberry Pi 4.

> **ğŸ‡®ğŸ‡¹ Un sistema AI innovativo che trasforma la visione in musica**  
> Riconoscimento oggetti in tempo reale e generazione musicale coerente, completamente offline su Raspberry Pi 4.

---

## ğŸ¥ Demo in Action | Demo dal Vivo

[![Demo Video](https://img.shields.io/badge/â–¶ï¸-Watch%20Demo-red?style=for-the-badge)](https://youtu.be/your-demo-link)

| ğŸ‡¬ğŸ‡§ Detected Object | ğŸ‡®ğŸ‡¹ Oggetto Rilevato | Generated Style | Audio Sample |
|---------------------|----------------------|-----------------|--------------|
| ğŸŒ± Plant | ğŸŒ± Pianta | Ambient, Relaxing | [â–¶ï¸ Listen](examples/plant_music.mp3) |
| ğŸ“š Book | ğŸ“š Libro | Classical, Contemplative | [â–¶ï¸ Listen](examples/book_music.mp3) |
| â˜• Cup | â˜• Tazza | Jazz, Intimate | [â–¶ï¸ Listen](examples/cup_music.mp3) |

---

## ğŸ§  System Architecture | Architettura del Sistema

```mermaid
graph LR
    A[Raspberry Pi Camera] --> B[PyTorch Object Detection]
    B --> C[Semantic Mapping Engine]
    C --> D[Magenta Music Generation]
    D --> E[TensorFlow Lite Inference]
    E --> F[MIDI/Audio Output]
    
    style A fill:#ff9999
    style F fill:#99ff99
```

### ğŸ”§ Technology Stack | Stack Tecnologico

**ğŸ‡¬ğŸ‡§ English:**
- **Computer Vision**: PyTorch + TorchVision (Optimized MobileNet V2)
- **AI Music**: Google Magenta converted to TensorFlow Lite
- **Hardware**: Raspberry Pi 4, Camera Module v2
- **Audio**: pretty_midi + FluidSynth for real-time synthesis
- **Optimizations**: INT8 quantization, Asynchronous pipeline

**ğŸ‡®ğŸ‡¹ Italiano:**
- **Computer Vision**: PyTorch + TorchVision (MobileNet V2 ottimizzato)
- **AI Music**: Google Magenta convertito in TensorFlow Lite
- **Hardware**: Raspberry Pi 4, Camera Module v2
- **Audio**: pretty_midi + FluidSynth per sintesi real-time
- **Ottimizzazioni**: Quantizzazione INT8, Pipeline asincrona

---

## ğŸ“Š Performance on Raspberry Pi 4 | Performance su Raspberry Pi 4

| Metric | ğŸ‡¬ğŸ‡§ Value | ğŸ‡®ğŸ‡¹ Valore |
|---------|------------|-------------|
| **Detection FPS** | 12-15 fps | 12-15 fps |
| **Generation Latency** | < 2 seconds | < 2 secondi |
| **RAM Usage** | ~1.4GB | ~1.4GB |
| **CPU Load** | 65-75% | 65-75% |
| **Boot Time** | ~15 seconds | ~15 secondi |

---

## ğŸµ Musical Output Examples | Esempi di Output Musicale

### ğŸ‡¬ğŸ‡§ Semantic Object â†’ Music Mapping

The system uses a proprietary algorithm to map visual features into musical parameters:

```python
# Conceptual example (proprietary implementation not public)
def object_to_music_params(detected_object):
    """
    Converts detected objects into musical parameters
    Proprietary logic not disclosed
    """
    semantic_features = extract_semantic_features(detected_object)
    musical_params = {
        'tempo': map_to_tempo(semantic_features.energy),
        'key': map_to_key(semantic_features.emotion),
        'instruments': select_instruments(semantic_features.category)
    }
    return musical_params
```

### ğŸ‡®ğŸ‡¹ Mappatura Semantica Oggetto â†’ Musica

Il sistema utilizza un algoritmo proprietario per mappare caratteristiche visive in parametri musicali:

```python
# Esempio concettuale (implementazione proprietaria non pubblica)
def object_to_music_params(detected_object):
    """
    Converte oggetti rilevati in parametri musicali
    Logica proprietaria non divulgata
    """
    semantic_features = extract_semantic_features(detected_object)
    musical_params = {
        'tempo': map_to_tempo(semantic_features.energy),
        'key': map_to_key(semantic_features.emotion),
        'instruments': select_instruments(semantic_features.category)
    }
    return musical_params
```

### ğŸ¼ Generated Compositions | Composizioni Generate

**ğŸ‡¬ğŸ‡§ Object: Potted Plant** ğŸŒ± | **ğŸ‡®ğŸ‡¹ Oggetto: Pianta in Vaso** ğŸŒ±
- **Style | Stile**: Ambient, New Age
- **Key | TonalitÃ **: C Major | Do Maggiore
- **Tempo**: 72 BPM
- **Instruments | Strumenti**: Synth pads, Soft strings | Pad sintetici, Archi soft

**ğŸ‡¬ğŸ‡§ Object: Open Book** ğŸ“– | **ğŸ‡®ğŸ‡¹ Oggetto: Libro Aperto** ğŸ“–
- **Style | Stile**: Neoclassical | Neoclassico
- **Key | TonalitÃ **: A minor | La minore
- **Tempo**: 60 BPM
- **Instruments | Strumenti**: Piano, String quartet | Pianoforte, Quartetto d'archi

---

## ğŸš€ Setup and Installation | Installazione e Configurazione

### ğŸ‡¬ğŸ‡§ Hardware Requirements | ğŸ‡®ğŸ‡¹ Requisiti Hardware

**ğŸ‡¬ğŸ‡§ English:**
- Raspberry Pi 4 (4GB RAM minimum)
- MicroSD 32GB+ (Class 10)
- Camera Module v2 or USB Camera
- USB Speaker or 3.5mm Jack

**ğŸ‡®ğŸ‡¹ Italiano:**
- Raspberry Pi 4 (4GB RAM minimo)
- MicroSD 32GB+ (Classe 10)
- Camera Module v2 o Camera USB
- Speaker USB o Jack 3.5mm

### Quick Installation | Installazione Rapida

```bash
# ğŸ‡¬ğŸ‡§ Clone demo repository | ğŸ‡®ğŸ‡¹ Clona il repository demo
git clone https://github.com/ninuxi/ai-audio-vision-lab.git
cd ai-audio-vision-lab

# ğŸ‡¬ğŸ‡§ Install dependencies | ğŸ‡®ğŸ‡¹ Installa le dipendenze
pip3 install -r requirements.txt

# ğŸ‡¬ğŸ‡§ Configure hardware | ğŸ‡®ğŸ‡¹ Configura hardware
sudo raspi-config  # Enable Camera | Abilita Camera

# ğŸ‡¬ğŸ‡§ Start demo | ğŸ‡®ğŸ‡¹ Avvia demo
python3 demo/simple_demo.py
```

### ğŸ‡¬ğŸ‡§ Automated Setup for Raspberry Pi | ğŸ‡®ğŸ‡¹ Setup Automatico per Raspberry Pi

```bash
# ğŸ‡¬ğŸ‡§ Run automated setup script | ğŸ‡®ğŸ‡¹ Esegui script di setup automatico
chmod +x scripts/setup_raspberry_pi.sh
./scripts/setup_raspberry_pi.sh
```

---

## ğŸ”¬ Research and Development | Ricerca e Sviluppo

### ğŸ‡¬ğŸ‡§ Original Technical Contributions | ğŸ‡®ğŸ‡¹ Contributi Tecnici Originali

**ğŸ‡¬ğŸ‡§ English:**

1. **Edge Computing Optimized Pipeline**
   - Custom quantization of Magenta models
   - Circular buffer for real-time processing
   - Intelligent memory mapping for Raspberry Pi

2. **Semantic Mapping Algorithm**
   - Object-emotion correlation based on cognitive research
   - Multi-dimensional musical parameterization
   - Temporal coherence system for smooth transitions

3. **Offline Inference Framework**
   - Zero cloud dependencies
   - Fully embedded models
   - Guaranteed <2s latency

**ğŸ‡®ğŸ‡¹ Italiano:**

1. **Pipeline Ottimizzata per Edge Computing**
   - Quantizzazione personalizzata dei modelli Magenta
   - Buffer circolare per elaborazione real-time
   - Memory mapping intelligente per Raspberry Pi

2. **Algoritmo di Mappatura Semantica**
   - Correlazione oggetto-emozione basata su ricerca cognitiva
   - Parametrizzazione musicale multi-dimensionale
   - Sistema di coerenza temporale per transizioni fluide

3. **Framework di Inferenza Offline**
   - Zero dipendenze cloud
   - Modelli completamente embedded
   - Latenza <2s garantita

### ğŸ“ˆ Future Roadmap | Roadmap Futura

- [ ] **ğŸ‡¬ğŸ‡§ Mobile Version | ğŸ‡®ğŸ‡¹ Versione Mobile**: Android/iOS porting
- [ ] **ğŸ‡¬ğŸ‡§ Multi-Modal | ğŸ‡®ğŸ‡¹ Multi-ModalitÃ **: Audio input + Visual input
- [ ] **ğŸ‡¬ğŸ‡§ Personalized Learning | ğŸ‡®ğŸ‡¹ Apprendimento Personalizzato**: User preference adaptation
- [ ] **ğŸ‡¬ğŸ‡§ ESP32 Port | ğŸ‡®ğŸ‡¹ Porting ESP32**: Ultra-compact version with TinyML

---

## ğŸ¤ Collaborations and Contact | Collaborazioni e Contatti

**ğŸ‡¬ğŸ‡§ Interested in collaborating? | ğŸ‡®ğŸ‡¹ Interessato a collaborare?**

**ğŸ‡¬ğŸ‡§ This project is open to:**
- ğŸ“ **Researchers** in AI/Music Information Retrieval
- ğŸµ **Musicians** interested in creative technologies
- ğŸ’» **Developers** with edge computing experience
- ğŸ¢ **Companies** for commercial applications

**ğŸ‡®ğŸ‡¹ Questo progetto Ã¨ aperto a:**
- ğŸ“ **Ricercatori** in AI/Music Information Retrieval
- ğŸµ **Musicisti** interessati a tecnologie creative
- ğŸ’» **Sviluppatori** con esperienza in edge computing
- ğŸ¢ **Aziende** per applicazioni commerciali

### ğŸ“§ Contact | Contatti
- **Email**: oggettosonoro@gmail.com  
- **GitHub**: [@ninuxi](https://github.com/ninuxi)
- **Portfolio**: [Complete portfolio link]

---

## âš–ï¸ License and Usage | Licenza e Utilizzo

**ğŸ‡¬ğŸ‡§ This repository contains a demonstration version of the AI Audio Vision Lab project.**

- âœ… **Demo and examples**: Freely usable (MIT License)
- âŒ **Complete source code**: Proprietary, not public
- ğŸ¤ **Commercial collaborations**: Contact for specific licenses

**ğŸ‡®ğŸ‡¹ Questo repository contiene una versione dimostrativa del progetto AI Audio Vision Lab.**

- âœ… **Demo ed esempi**: Liberamente utilizzabili (Licenza MIT)
- âŒ **Codice sorgente completo**: Proprietario, non pubblico
- ğŸ¤ **Collaborazioni commerciali**: Contatta per licenze specifiche

> **ğŸ‡¬ğŸ‡§ Note**: Core algorithms and trained models represent original research and are not publicly available. For full access or commercial partnerships, contact the author directly.

> **ğŸ‡®ğŸ‡¹ Nota**: Gli algoritmi core e i modelli addestrati rappresentano ricerca originale e non sono pubblicamente disponibili. Per accesso completo o partnership commerciali, contatta direttamente l'autore.

---

## ğŸŒŸ Acknowledgments | Riconoscimenti

**ğŸ‡¬ğŸ‡§ Project developed by** **Antonio Mainenti** (2024-2025)  
**ğŸ‡®ğŸ‡¹ Progetto sviluppato da** **Antonio Mainenti** (2024-2025)

*ğŸ‡¬ğŸ‡§ If this project inspires you, leave a â­ and share it!*  
*ğŸ‡®ğŸ‡¹ Se questo progetto ti ispira, lascia una â­ e condividilo!*

---

**Â© 2025 Antonio Mainenti - Some rights reserved | Alcuni diritti riservati**

---

## ğŸ“š Complete Documentation | Documentazione Completa

**ğŸ‡¬ğŸ‡§ For complete documentation:**
- [ğŸ“– Architecture Guide](docs/architecture.md)
- [ğŸ› ï¸ Installation Guide](docs/installation.md)
- [ğŸ¯ API Reference](docs/api_reference.md)
- [ğŸ”¬ Research Background](docs/research_background.md)

**ğŸ‡®ğŸ‡¹ Per la documentazione completa:**
- [ğŸ“– Guida Architettura](docs/architecture.md)
- [ğŸ› ï¸ Guida Installazione](docs/installation.md)
- [ğŸ¯ Riferimento API](docs/api_reference.md)
- [ğŸ”¬ Background di Ricerca](docs/research_background.md)

---

## ğŸ¯ Quick Links | Link Rapidi

| ğŸ‡¬ğŸ‡§ English | ğŸ‡®ğŸ‡¹ Italiano | Link |
|-------------|--------------|------|
| Demo Script | Script Demo | [demo/simple_demo.py](demo/simple_demo.py) |
| Setup Guide | Guida Setup | [scripts/setup_raspberry_pi.sh](scripts/setup_raspberry_pi.sh) |
| Contributing | Contribuire | [CONTRIBUTING.md](CONTRIBUTING.md) |
| License | Licenza | [LICENSE](LICENSE) |
| Issues | Problemi | [GitHub Issues](https://github.com/ninuxi/ai-audio-vision-lab/issues) |
| Discussions | Discussioni | [GitHub Discussions](https://github.com/ninuxi/ai-audio-vision-lab/discussions) |

---

*ğŸ‡¬ğŸ‡§ Built with â¤ï¸ for the intersection of AI, Music, and Creative Technology*  
*ğŸ‡®ğŸ‡¹ Costruito con â¤ï¸ per l'intersezione tra AI, Musica e Tecnologie Creative*